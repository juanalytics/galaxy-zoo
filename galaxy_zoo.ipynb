{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ea3b5e",
   "metadata": {
    "id": "82ea3b5e"
   },
   "source": [
    "# **Entendimiento del Negocio y Carga de Datos**\n",
    "---\n",
    "\n",
    "- **Andrés Felipe Rosada**\n",
    "- **Sergio Motta Doncel**\n",
    "- **Angel Olivera Pinzón**\n",
    "- **Juan Manuel Pérez**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4c33d",
   "metadata": {
    "id": "fdb4c33d"
   },
   "source": [
    "## **1. Marco de Proyecto**\n",
    "---\n",
    "\n",
    "### **Desafío Galaxy Zoo.**\n",
    "\n",
    "El Galaxy Zoo Challenge de Kaggle es un proyecto que busca describir galaxias observadas en el cielo nocturno a través de una innovadora herramienta de colaboración colectiva. En esta iniciativa, los usuarios analizan imágenes astronómicas respondiendo a una serie de preguntas sobre las características morfológicas que observan.\n",
    "\n",
    "El conjunto de datos contiene 61.578 imágenes, cada una acompañada de sus respectivas etiquetas. Estas etiquetas están organizadas en 37 clases con el formato \"ClaseA.B\", donde A representa una pregunta (del 1 al 11) y B corresponde a una de sus posibles opciones. A diferencia de un problema clásico de clasificación, en este caso cada clase representa un atributo específico y la mayoría de las imágenes presentan múltiples atributos simultáneamente.\n",
    "\n",
    "Los valores asociados a cada clase reflejan el nivel de confianza colectiva (entre 0 y 1) de que una determinada respuesta es correcta. Cabe destacar que el sistema de clasificación utiliza un árbol de decisión dinámico, en el que las preguntas mostradas al usuario dependen de sus respuestas anteriores, por lo que no todos los participantes ven las mismas preguntas para cada imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a974ec1",
   "metadata": {
    "id": "7a974ec1"
   },
   "source": [
    "### **1.1. Trasfondo del Negocio**\n",
    "---\n",
    "\n",
    "- ¿Quién es el cliente o los beneficiarios del proyecto? ¿En qué dominio se encuentran (marketing, medicina, entre otros)?\n",
    "- ¿Qué problemas del negocio o del dominio estamos tratando de solucionar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9305a",
   "metadata": {
    "id": "18d9305a"
   },
   "source": [
    "Los principales beneficiarios del proyecto Galaxy Zoo son la comunidad científica astronómica y, en particular, los investigadores en el área de la astrofísica observacional y la morfología galáctica. Este proyecto también beneficia a instituciones académicas, observatorios astronómicos, centros de investigación, y a la comunidad de ciencia ciudadana que participa activamente en la clasificación de galaxias.\n",
    "\n",
    "El dominio del proyecto es claramente científico, específicamente en el campo de la astronomía y la astroinformática. Claramente es un proyecto que se relaciona de manera indirecta con el área de inteligencia artificial y la ciencia de datos, ya que el problema de clasificación automática de galaxias implica técnicas avanzadas de aprendizaje automático y procesamiento de imágenes.\n",
    "\n",
    "Adicionalmente el proyecto tiene un impacto significativo en la educación científica y en la divulgación del conocimiento, al involucrar a ciudadanos comunes en un proceso colaborativo de descubrimiento, lo que fortalece el vínculo entre ciencia y sociedad.\n",
    "\n",
    "Este proyecto aborda varios problemas fundamentales en el dominio de la astronomía observacional:\n",
    "\n",
    " - **Escalabilidad del análisis morfológico de galaxias:** En la era de los grandes observatorios y telescopios digitales, como el Sloan Digital Sky Survey (SDSS), se generan millones de imágenes astronómicas. Clasificar manualmente cada galaxia es inviable para un número reducido de expertos. Galaxy Zoo plantea una solución basada en la inteligencia colectiva y, posteriormente, en el entrenamiento de modelos automáticos capaces de replicar estas clasificaciones con alta precisión.\n",
    "\n",
    " - **Automatización de tareas cognitivamente complejas:** Aunque existen modelos de clasificación automática de imágenes, las estructuras morfológicas de las galaxias (espirales, elípticas, interacciones, barras, etc.) pueden ser sutiles y requieren un juicio visual refinado. El proyecto ayuda a generar datos etiquetados de alta calidad que pueden ser usados para entrenar modelos más robustos, basados en aprendizaje profundo.\n",
    "\n",
    " - **Generación de conocimiento científico:** Al sistematizar y clasificar una gran cantidad de galaxias, el proyecto permite estudiar la distribución y evolución de estas estructuras en el universo, lo que contribuye directamente a responder preguntas sobre la formación galáctica, la materia oscura, y la evolución cósmica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c63e5",
   "metadata": {
    "id": "d09c63e5"
   },
   "source": [
    "### **1.2. Alcance**\n",
    "---\n",
    "\n",
    "- ¿Qué  solución basada en _Deep Learning_ queremos implementar?\n",
    "- ¿Qué  se hará?\n",
    "- ¿De qué forma el cliente o beneficiario utilizará el producto del proyecto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3be6b",
   "metadata": {
    "id": "12e3be6b"
   },
   "source": [
    "La solución que se plantea implementar es un modelo de clasificación de imágenes astronómicas basado en redes neuronales convolucionales (CNNs), entrenado con los datos etiquetados del proyecto Galaxy Zoo. Este modelo tendrá como objetivo predecir las características morfológicas de las galaxias directamente a partir de las imágenes, emulando y automatizando el trabajo previamente realizado por miles de voluntarios a través de la plataforma de ciencia ciudadana.\n",
    "\n",
    "Se busca desarrollar una arquitectura que pueda capturar tanto las características locales (como los brazos espirales o núcleos brillantes) como las estructuras globales (como la simetría, orientación o interacción entre galaxias), que son fundamentales para la clasificación morfológica.\n",
    "\n",
    "Para llevar a cabo este proyecto, se desarrollará un flujo de trabajo estructurado que abarca desde el preprocesamiento de los datos hasta la obtención de un modelo funcional basado en deep learning. En primer lugar, se realizará el preprocesamiento del conjunto de datos, lo cual incluye la carga y limpieza de las imágenes y sus respectivas etiquetas, así como el redimensionamiento y la normalización de las imágenes para adaptarlas a los requerimientos del modelo. Además, será necesario convertir las etiquetas probabilísticas proporcionadas por el conjunto original en un formato compatible con el aprendizaje supervisado, considerando que cada imagen puede contener múltiples atributos con valores continuos.\n",
    "\n",
    "Una vez preparados los datos, se procederá al diseño y entrenamiento del modelo de deep learning, utilizando una arquitectura de red neuronal convolucional (CNN) adecuada para la clasificación de imágenes. Se evaluará el uso de arquitecturas ya consolidadas, aunque también se considerará la posibilidad de desarrollar una arquitectura personalizada que se ajuste mejor a la naturaleza del problema. El modelo se entrenará sobre un subconjunto del total de datos etiquetados y se validará utilizando otro subconjunto independiente, empleando métricas adecuadas para su evaluación. Evaluación que sera exhaustiva, tanto a través de análisis cuantitativos como mediante la inspección visual de los resultados. Esta fase permitirá comparar el desempeño del modelo propuesto con métodos tradicionales o baselines sin técnicas de deep learning, con el fin de demostrar su efectividad y ventajas concretas.\n",
    "\n",
    "El producto final permitirá a astrónomos profesionales, investigadores y centros de datos astronómicos analizar de manera automática grandes volúmenes de imágenes de galaxias, acelerando el proceso de clasificación y reduciendo la dependencia del etiquetado manual.\n",
    "\n",
    "Además: Investigadores podrán usar el modelo como una herramienta de apoyo para prefiltrar o clasificar nuevos conjuntos de datos provenientes de futuros telescopios (por ejemplo, LSST, Euclid o JWST), permitiéndoles centrar sus esfuerzos en objetos astronómicamente más interesantes o inusuales.\n",
    "\n",
    "Educadores y divulgadores científicos podrían usar el sistema como ejemplo de cómo la inteligencia artificial se aplica en la astronomía moderna, incentivando el interés en la ciencia y la tecnología.\n",
    "\n",
    "El modelo también puede ser reutilizado o adaptado para otras tareas dentro del campo, como detección de objetos raros, clasificación de cúmulos o análisis de estructuras de colisión galáctica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e4a5d",
   "metadata": {
    "id": "370e4a5d"
   },
   "source": [
    "### **1.3. Plan**\n",
    "---\n",
    "\n",
    "Puede agregar una lista de actividades con tiempos estimados, un diagrama de Gantt o integrar alguna herramienta de gestión de proyectos para mostrar la planeación del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b465355",
   "metadata": {
    "id": "3b465355"
   },
   "source": [
    "| **Fase**                               | **Descripción**                                                            | **Duración (horas)** |\n",
    "| -------------------------------------- | -------------------------------------------------------------------------- | -------------------- |\n",
    "| **1. Entendimiento del problema**      | Analizar los objetivos de Galaxy Zoo y definición del alcance del proyecto | 4                    |\n",
    "| **2. Exploración de los datos**        | Análisis del dataset de imágenes galácticas, revisión de etiquetas y tipos | 6                    |\n",
    "| **3. Preprocesamiento de datos**       | Limpieza, normalización y preparación de las imágenes para el modelo       | 6                    |\n",
    "| **4. Diseño y preparación del modelo** | Selección y carga de modelo base para clasificación de galaxias            | 5                    |\n",
    "| **5. Entrenamiento del modelo**        | Ajuste y entrenamiento del modelo con el dataset procesado                 | 14                   |\n",
    "| **6. Evaluación y ajuste**             | Evaluación del rendimiento, ajuste de hiperparámetros y validación         | 8                    |\n",
    "| **7. Documentación y presentación**    | Preparación de informes, visualización de resultados y presentación final  | 4                    |\n",
    "\n",
    "\n",
    "Fecha estimada de entrega: 4 semanas a partir del inicio del proyecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e145b",
   "metadata": {
    "id": "4a4e145b"
   },
   "source": [
    "## **2. Datos**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f8274",
   "metadata": {
    "id": "2c5f8274"
   },
   "source": [
    "### **2.1. Origen**\n",
    "---\n",
    "\n",
    "- ¿De dónde vienen los datos?\n",
    "- ¿Se usa alguna herramienta o proceso para la descarga de la información?\n",
    "- ¿Qué tipo de datos estamos manejando?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261ad96",
   "metadata": {
    "id": "7261ad96"
   },
   "source": [
    "Los datos utilizados en este proyecto provienen del Galaxy Zoo Challenge, un conjunto de datos publicado en la plataforma Kaggle, el cual forma parte de una iniciativa de ciencia ciudadana desarrollada por el proyecto Galaxy Zoo en colaboración con Zooniverse. Esta iniciativa invita al público a colaborar en la clasificación morfológica de galaxias observadas en el cielo nocturno, proporcionando un repositorio amplio de imágenes astronómicas junto con las etiquetas generadas a partir de las respuestas agregadas de miles de voluntarios.\n",
    "\n",
    "Para acceder a la información, se emplea el API de Kaggle, una herramienta que permite descargar de forma automática los datos directamente desde la plataforma hacia un entorno de trabajo como Google Colab. Este proceso requiere autenticar al usuario mediante un archivo de credenciales (kaggle.json), que contiene la clave y el nombre de usuario, y luego ejecutar comandos específicos para descargar y descomprimir el dataset.\n",
    "\n",
    "El tipo de datos que se maneja en este proyecto es principalmente multimedia y tabular. Por un lado, se cuenta con 61.578 imágenes de galaxias en formato JPEG, las cuales constituyen la entrada visual para el modelo de clasificación. Por otro lado, se dispone de un archivo tabular que contiene las etiquetas asociadas a cada imagen, representadas como valores continuos entre 0 y 1 que indican el nivel de confianza colectiva asignado a distintas clases morfológicas. Estas clases corresponden a las respuestas posibles a un conjunto de preguntas jerárquicas (del tipo “¿La galaxia tiene forma de espiral?” o “¿Tiene barra central?”), lo que convierte el problema en una clasificación multi-etiqueta con valores probabilísticos en lugar de un caso clásico de clasificación simple.\n",
    "\n",
    "En conjunto, este conjunto de datos constituye una base rica y compleja que permite entrenar modelos de aprendizaje profundo capaces de emular el juicio colectivo humano en la clasificación de estructuras galácticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cc180",
   "metadata": {
    "id": "4a9cc180"
   },
   "source": [
    "### **2.2. Carga o Adquisición de Datos**\n",
    "---\n",
    "\n",
    "Agregue el código necesario en _Python_ para obtener o cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b580368",
   "metadata": {
    "id": "1b580368"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/SergioIvanMottaDonce/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# INGRESE SU CÓDIGO\n",
    "!pip install -q kaggle\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PAglMHaAyqjH",
   "metadata": {
    "id": "PAglMHaAyqjH"
   },
   "outputs": [],
   "source": [
    "# Cargar el archivo kaggle.json al directorio correcto para su configuración\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cNOwqiC4yCRO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNOwqiC4yCRO",
    "outputId": "6c614225-fb71-4c69-ab97-f48ae55d99c6"
   },
   "outputs": [],
   "source": [
    "# Descargar dataset desde Kaggle\n",
    "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fOLDUva0yLB-",
   "metadata": {
    "id": "fOLDUva0yLB-"
   },
   "outputs": [],
   "source": [
    "# Descomprimir los archivos ZIP\n",
    "with zipfile.ZipFile(\"galaxy-zoo-the-galaxy-challenge.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"galaxy_zoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1OKcAZYyS_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1OKcAZYyS_u",
    "outputId": "ab1509c0-af3e-40a4-e583-2b5bb31eae08"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "# Carpeta con archivos zip extraídos inicialmente\n",
    "base_folder = \"galaxy_zoo\"\n",
    "# Recorremos todos los archivos dentro de la carpeta base\n",
    "for filename in os.listdir(base_folder):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        file_path = os.path.join(base_folder, filename)\n",
    "        print(f\"Extrayendo {file_path} ...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            # Extraer contenido en la misma carpeta base_folder\n",
    "            zip_ref.extractall(base_folder)\n",
    "        print(f\"{filename} extraído correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N8zY6T95yzxA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "N8zY6T95yzxA",
    "outputId": "7eaef2a2-4ce4-446a-99df-9969fe790ba8"
   },
   "outputs": [],
   "source": [
    "# Cargamos etiquetas (probabilidades por clase para cada imagen)\n",
    "labels_df = pd.read_csv(\"galaxy_zoo/training_solutions_rev1.csv\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-yGgtvtRy11j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-yGgtvtRy11j",
    "outputId": "ba2214be-4585-4832-987f-e5839923831a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_folder = \"galaxy_zoo/images_training_rev1/\"\n",
    "\n",
    "num_images = 10  # Definimos una muestra de 10 imágenes para mostrarla.\n",
    "\n",
    "for idx in range(num_images):\n",
    "    row = labels_df.iloc[idx]\n",
    "    image_name = str(int(row[\"GalaxyID\"]))\n",
    "    image_path = os.path.join(image_folder, f\"{image_name}.jpg\")\n",
    "\n",
    "    # Cargar y mostrar las imagenes\n",
    "    image = Image.open(image_path)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Galaxy ID: {image_name}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Mostrar las probabilidades asignadas por los usuarios a cada categoria (excluyendo GalaxyID)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    row.drop(\"GalaxyID\").plot(kind=\"bar\")\n",
    "    plt.title(\"Etiquetas (Probabilidades)\")\n",
    "    plt.ylabel(\"Probabilidad\")\n",
    "    plt.xlabel(\"Clase\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AcjO-YZw3HBr",
   "metadata": {
    "id": "AcjO-YZw3HBr"
   },
   "source": [
    "**Caracteristica de las imagenes mostradas en el dataset:**\n",
    "\n",
    " - Formato: Son archivos JPEG (.jpg), un formato común para imágenes con compresión con pérdida que equilibra calidad y tamaño.\n",
    "\n",
    " - Dimensiones: Normalmente son imágenes de tamaño fijo o similar, por ejemplo, 424 x 424 píxeles o cercanos (esto puede variar según la fuente o versión del dataset). Las imágenes muestran galaxias centradas en el encuadre.\n",
    "\n",
    " - Color: Son imágenes a color (RGB), con 3 canales que representan las bandas de luz captadas (aunque a veces podrían ser en escala de grises si se usan imágenes de ciertas longitudes de onda).\n",
    "\n",
    " - Contenido: Cada imagen contiene una galaxia o una región del cielo con una galaxia visible. Pueden mostrar diferentes tipos morfológicos: espirales, elípticas, irregulares, galaxias con barras, etc.\n",
    "\n",
    " - Calidad y resolución: Son imágenes tomadas con instrumentos astronómicos profesionales, por lo que la calidad suele ser alta, aunque con ruido propio de observaciones astronómicas. Pueden contener artefactos o ruido, como estrellas de campo o errores de imagen.\n",
    "\n",
    " - Etiquetas asociadas: Cada imagen tiene etiquetas con probabilidades continuas que representan la confianza colectiva de usuarios en ciertas características morfológicas, no etiquetas binarias estrictas.\n",
    "\n",
    " - Propósito: Son imágenes usadas para tareas de clasificación morfológica, detección y análisis automático mediante aprendizaje supervisado o métodos tradicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9669dfd",
   "metadata": {
    "id": "a9669dfd"
   },
   "source": [
    "# **Entendimiento y Preparación de los Datos**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de2158",
   "metadata": {
    "id": "f6de2158"
   },
   "source": [
    "## **1. Análisis Exploratorio de los Datos**\n",
    "---\n",
    "\n",
    "Normalmente en el análisis exploratorio, se trata de dar respuesta a los siguientes elementos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20031c7b",
   "metadata": {
    "id": "20031c7b"
   },
   "source": [
    "### **1.1. Resumen General**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f9910",
   "metadata": {
    "id": "8b0f9910"
   },
   "source": [
    "---**Importación del Dataset Completo**---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oBdZH7Lhn7xS",
   "metadata": {
    "id": "oBdZH7Lhn7xS"
   },
   "outputs": [],
   "source": [
    "# INGRESE SU CÓDIGO\n",
    "!pip install -q kaggle\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GkBxF2DLoGbn",
   "metadata": {
    "id": "GkBxF2DLoGbn"
   },
   "outputs": [],
   "source": [
    "# Cargar el archivo kaggle.json al directorio correcto para su configuración\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VlZ3rrIoTKD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "9VlZ3rrIoTKD",
    "outputId": "8b5be0b1-bcc6-42fe-e442-243056d9ed0b"
   },
   "outputs": [],
   "source": [
    "# Descargar dataset desde Kaggle\n",
    "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge\n",
    "# Descomprimir los archivos ZIP\n",
    "with zipfile.ZipFile(\"galaxy-zoo-the-galaxy-challenge.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"galaxy_zoo\")\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "# Carpeta con archivos zip extraídos inicialmente\n",
    "base_folder = \"galaxy_zoo\"\n",
    "# Recorremos todos los archivos dentro de la carpeta base\n",
    "for filename in os.listdir(base_folder):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        file_path = os.path.join(base_folder, filename)\n",
    "        print(f\"Extrayendo {file_path} ...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            # Extraer contenido en la misma carpeta base_folder\n",
    "            zip_ref.extractall(base_folder)\n",
    "        print(f\"{filename} extraído correctamente.\")\n",
    "\n",
    "# Cargamos etiquetas (probabilidades por clase para cada imagen)\n",
    "labels_df = pd.read_csv(\"galaxy_zoo/training_solutions_rev1.csv\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DyBTXenvpAn7",
   "metadata": {
    "id": "DyBTXenvpAn7"
   },
   "source": [
    "- ¿Cuántos documentos tiene el dataset?\n",
    "- ¿En qué formato están guardados los datos?\n",
    "- ¿Qué tamaño en MB tiene el conjunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VDEv4MX9pJk8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDEv4MX9pJk8",
    "outputId": "9855cb48-98b1-4d52-9234-f597f97ffb3a"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# Contar archivos .jpg en todas las subcarpetas\n",
    "image_files = glob.glob(\"galaxy_zoo/**/*.jpg\", recursive=True)\n",
    "print(f\"Número de imágenes: {len(image_files)}\")\n",
    "\n",
    "file_extensions = set()\n",
    "for root, dirs, files in os.walk(\"galaxy_zoo\"):\n",
    "    for f in files:\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        file_extensions.add(ext)\n",
    "\n",
    "print(f\"Formatos de archivos en la carpeta del proyecto: {file_extensions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "udwqRugnpupv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udwqRugnpupv",
    "outputId": "ffa19774-a972-4b03-db1d-06b2b4e8ef24"
   },
   "outputs": [],
   "source": [
    "def folder_size_mb(folder):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size / (1024 * 1024)  # Convertir a MB\n",
    "\n",
    "dataset_size_mb = folder_size_mb(\"galaxy_zoo\")\n",
    "print(f\"Tamaño total del dataset: {dataset_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KpUw3ghDqpw8",
   "metadata": {
    "id": "KpUw3ghDqpw8"
   },
   "source": [
    "Luego de descargar y explorar el conjunto de datos del Galaxy Zoo: The Galaxy Challenge, se identificaron aspectos clave que permiten caracterizar su estructura, volumen y naturaleza, lo cual es fundamental para orientar las etapas posteriores de análisis y modelado. En total, el dataset contiene 141,553 imágenes en formato .jpg, correspondientes a observaciones astronómicas de galaxias. Estas imágenes están organizadas principalmente en las carpetas images_training_rev1 y iamges_test_rev1, y constituyen el insumo esencial para desarrollar tareas de clasificación morfológica automatizada. El conjunto completo ocupa aproximadamente 3,729.12 MB (alrededor de 3.73 GB), lo que implica que cualquier procesamiento deberá considerar estrategias de eficiencia computacional, es mejor tener acceso a GPUs.\n",
    "\n",
    "En cuanto a los formatos de archivo presentes, se identificaron extensiones .jpg, .csv y .zip. Las imágenes están acompañadas de archivos de etiquetas en formato .csv, denominados training_solutions_rev1.csv y test_solutions_rev1.csv, que contiene las salidas deseadas para cada imagen en forma de vectores de probabilidad. Este diseño particular del conjunto lo diferencia de problemas clásicos de clasificación, ya que no se asigna una sola categoría a cada imagen, sino una distribución de probabilidad sobre 37 posibles clases morfológicas. Esto sugiere que el problema puede abordarse como una regresión multietiqueta o como una clasificación probabilística, requiriendo técnicas de modelado capaces de aproximar distribuciones, en lugar de simplemente predecir clases discretas.\n",
    "\n",
    "La presencia de archivos .zip corresponde a empaquetados intermedios utilizados durante la descarga. Una vez extraídos, estos archivos pueden eliminarse para liberar espacio en disco, ya que no aportan valor adicional al análisis. En términos de preprocesamiento, las imágenes requieren transformación para ser utilizadas en modelos de aprendizaje profundo, lo cual incluye redimensionamiento, normalización de píxeles y eventualmente técnicas de data augmentation para mejorar la generalización del modelo. A su vez, se deberá asegurar la correcta alineación entre las imágenes y sus respectivas etiquetas, algo especialmente importante dado el gran volumen de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ad6f5",
   "metadata": {
    "id": "447ad6f5"
   },
   "source": [
    "### **1.2. Resumen de la Calidad de los datos**\n",
    "---\n",
    "\n",
    "- ¿Hay datos faltantes, documentos vacíos o de mala calidad?\n",
    "- ¿Existen documentos ilegibles o con problemas de codificación?\n",
    "- ¿Hay mezcla de formatos en el conjunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0usPy1JhrcpN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0usPy1JhrcpN",
    "outputId": "a91fd34f-bb75-4510-a5bb-1c05382249b4"
   },
   "outputs": [],
   "source": [
    "# Cargar etiquetas\n",
    "labels_df = pd.read_csv(\"galaxy_zoo/training_solutions_rev1.csv\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "missing_data = labels_df.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Verificar si hay filas incompletas\n",
    "incomplete_rows = labels_df[labels_df.isnull().any(axis=1)]\n",
    "print(f\"\\nFilas incompletas: {len(incomplete_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SZrX4QyBrkU7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZrX4QyBrkU7",
    "outputId": "668075c8-5d3c-4668-a646-df32dd0f4299"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "image_folder = \"galaxy_zoo/images_training_rev1\"\n",
    "corrupt_files = []\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        file_path = os.path.join(image_folder, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()  # Verifica formato sin cargar toda la imagen\n",
    "        except Exception as e:\n",
    "            print(f\"Imagen corrupta: {filename} ({e})\")\n",
    "            corrupt_files.append(filename)\n",
    "\n",
    "print(f\"\\nTotal de imágenes corruptas: {len(corrupt_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_H36_lpDrpcX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H36_lpDrpcX",
    "outputId": "3dc449e2-5f41-47a8-804c-4ecb44852d00"
   },
   "outputs": [],
   "source": [
    "empty_files = []\n",
    "\n",
    "for root, _, files in os.walk(\"galaxy_zoo\"):\n",
    "    for f in files:\n",
    "        full_path = os.path.join(root, f)\n",
    "        if os.path.getsize(full_path) == 0:\n",
    "            empty_files.append(full_path)\n",
    "\n",
    "print(f\"\\nArchivos vacíos encontrados: {len(empty_files)}\")\n",
    "for f in empty_files:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XcGguJFhrufV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcGguJFhrufV",
    "outputId": "f265d925-a478-4344-82da-8833806d2211"
   },
   "outputs": [],
   "source": [
    "# Reintento de carga con validación de codificación\n",
    "try:\n",
    "    df_check = pd.read_csv(\"galaxy_zoo/training_solutions_rev1.csv\", encoding=\"utf-8\")\n",
    "    print(\"El archivo CSV tiene codificación UTF-8 válida.\")\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"Problema de codificación detectado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KITfG0F4ryI6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KITfG0F4ryI6",
    "outputId": "9e2bd019-0fba-4bc5-8fa6-93c0feb815f9"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "extensiones = defaultdict(int)\n",
    "\n",
    "for root, _, files in os.walk(\"galaxy_zoo\"):\n",
    "    for f in files:\n",
    "        _, ext = os.path.splitext(f)\n",
    "        extensiones[ext.lower()] += 1\n",
    "\n",
    "print(\"Tipos de archivos en el dataset:\")\n",
    "for ext, count in extensiones.items():\n",
    "    print(f\"{ext}: {count} archivos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fzz14NIOr5yJ",
   "metadata": {
    "id": "fzz14NIOr5yJ"
   },
   "source": [
    "Con el objetivo de garantizar la calidad y consistencia del dataset Galaxy Zoo: The Galaxy Challenge, se realizó una evaluación detallada enfocada en la detección de datos faltantes, archivos corruptos o ilegibles, y posibles inconsistencias de formato. Esta validación es crítica antes de avanzar a etapas de modelado, ya que errores en la integridad de los datos pueden comprometer el rendimiento del modelo y sesgar los resultados.\n",
    "\n",
    "En primer lugar, se analizó la presencia de datos faltantes en el archivo de etiquetas training_solutions_rev1.csv. A través de una inspección utilizando herramientas como pandas, se comprobó que no existen valores nulos o ausentes en las columnas que contienen las probabilidades morfológicas. Cada fila de este archivo representa una imagen única, identificada por su nombre, y está acompañada de 37 columnas con probabilidades, todas completas. Esto sugiere que, en términos de anotaciones, el conjunto de datos se encuentra completo y sin pérdidas de información evidentes.\n",
    "\n",
    "En cuanto a los documentos vacíos o ilegibles, se implementó un procedimiento automatizado para verificar la integridad de las imágenes. Este proceso recorrió el directorio images_training_rev1, cargando cada imagen mediante librerías como PIL o OpenCV y reportando cualquier excepción de lectura. No se encontraron imágenes corruptas ni archivos con tamaño cero bytes, lo cual indica que no hay documentos vacíos ni dañados. Además, se confirmó que todos los archivos .jpg presentan dimensiones válidas y contenido visual interpretable, por lo que no existen documentos ilegibles desde el punto de vista técnico.\n",
    "\n",
    "Respecto a la codificación y formatos, no se identificaron problemas de codificación textual en el archivo .csv, el cual utiliza una codificación estándar (utf-8) y se carga correctamente sin necesidad de ajustes adicionales. Por otra parte, el conjunto no presenta mezcla problemática de formatos: aunque coexisten archivos .jpg, .csv y .zip, estos cumplen funciones distintas (imágenes, etiquetas y compresión inicial, respectivamente), y están claramente separados por tipo. No hay evidencia de documentos etiquetados incorrectamente o con extensiones que no correspondan a su contenido real.\n",
    "\n",
    "El análisis de calidad muestra que el dataset se encuentra en muy buen estado: no hay datos faltantes ni etiquetas incompletas, las imágenes están disponibles y legibles, y no se presentan problemas de codificación ni mezcla de formatos que afecten la estructura del conjunto. Este diagnóstico positivo permite avanzar con confianza hacia las etapas de exploración visual, preprocesamiento de imágenes y entrenamiento de modelos, sin requerir una fase intensiva de limpieza o corrección de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec109",
   "metadata": {
    "id": "e90ec109"
   },
   "source": [
    "### **1.3. Tipos de variables**\n",
    "---\n",
    "\n",
    "- ¿El conjunto de datos tiene una variable objetivo a estimar?, de ser así, ¿es una variable continúa o categórica?\n",
    "- Analice la distribución de las etiquetas, identifique si hay desbalanceo de datos.\n",
    "- ¿El conjunto de datos cuenta con otras variables adicionales?, de ser así, debe analizar cuáles se incorporarán en el modelo y hacer un análisis descriptivo de las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c26982",
   "metadata": {
    "id": "d0c26982"
   },
   "source": [
    "\n",
    "En el dataset training_solutions_rev1.csv, cada fila contiene un identificador de imagen y 37 columnas que representan probabilidades de pertenencia a diferentes clases morfológicas. Esto significa que la variable objetivo no es una sola columna, sino un vector de probabilidades. Lo que un caso de regresión multietiqueta continua, donde cada imagen tiene múltiples probabilidades (valores entre 0 y 1) asociadas a distintas categorías morfológicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "axjbe5iJsY9k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axjbe5iJsY9k",
    "outputId": "bba26314-aafd-4606-f582-602f305bfdf8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=labels_df\n",
    "# Verificar dimensiones\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "\n",
    "# Inspeccionar las primeras columnas\n",
    "print(\"Primeras columnas:\")\n",
    "print(df.columns[:10])\n",
    "\n",
    "# Verificar si las columnas posteriores contienen valores entre 0 y 1\n",
    "label_columns = df.columns[1:]  # Excluyendo el ID de imagen\n",
    "\n",
    "continuous_check = df[label_columns].applymap(lambda x: 0.0 <= x <= 1.0).all().all()\n",
    "print(f\"\\n¿Todas las etiquetas están entre 0 y 1? {continuous_check}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sljrlgtVsm-8",
   "metadata": {
    "id": "sljrlgtVsm-8"
   },
   "source": [
    "Vamos a graficar la suma promedio de cada clase para ver si algunas clases tienen valores significativamente más altos (más frecuentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3TR6jxYUsoG1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "3TR6jxYUsoG1",
    "outputId": "4bdb5b23-dc03-4867-9029-4aa502d66223"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sumar promedios por clase (valor medio de probabilidad)\n",
    "label_means = df[label_columns].mean().sort_values(ascending=False)\n",
    "\n",
    "# Gráfico de barras\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_means.plot(kind='bar')\n",
    "plt.title(\"Distribución promedio de las etiquetas (probabilidades por clase)\")\n",
    "plt.xlabel(\"Clases morfológicas\")\n",
    "plt.ylabel(\"Promedio de probabilidad\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LGaZcstZtJV2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGaZcstZtJV2",
    "outputId": "37174820-e661-42a3-8101-d5525495f7f4"
   },
   "outputs": [],
   "source": [
    "# Mostrar todas las columnas\n",
    "print(\"Todas las columnas del dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Verificar si hay columnas adicionales además del ID y etiquetas\n",
    "non_label_columns = df.columns.difference(label_columns)\n",
    "print(f\"\\nColumnas no objetivo: {list(non_label_columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IacJIxB5tFNR",
   "metadata": {
    "id": "IacJIxB5tFNR"
   },
   "source": [
    "El conjunto de datos training_solutions_rev1.csv contiene información morfológica asociada a un gran número de galaxias, representadas por imágenes. Cada entrada del archivo incluye un identificador único de imagen (GalaxyID) y un conjunto de 37 columnas adicionales que expresan probabilidades asignadas a diversas clases morfológicas (por ejemplo: si la galaxia tiene brazos espirales, si es elíptica, si está interactuando, etc.).\n",
    "\n",
    "Este tipo de estructura indica que la variable objetivo no es una sola columna categórica, sino un vector continuo de múltiples dimensiones, donde cada elemento representa la probabilidad de pertenencia de la imagen a una determinada clase. En consecuencia, este es un caso de regresión multietiqueta continua, en el que se busca estimar un conjunto de valores numéricos entre 0 y 1 para cada observación.\n",
    "\n",
    "Para evaluar la distribución de estas variables objetivo, se calcularon los promedios de probabilidad por clase. El análisis mostró que algunas clases presentan valores promedio significativamente más altos que otras. Esta evidencia indica la presencia de desbalanceo en los datos, ya que ciertas clases aparecen con mayor frecuencia o mayor confianza que otras. Este desbalanceo debe ser considerado cuidadosamente durante el proceso de modelado, ya que podría sesgar el entrenamiento de modelos predictivos si no se aplica una estrategia adecuada de ponderación o muestreo.\n",
    "\n",
    "En cuanto a la estructura del dataset, se verificó que no existen variables adicionales además del identificador de imagen y las columnas de etiquetas. No se incluyen variables explicativas externas, como características físicas de las galaxias, metadatos astronómicos o información extra derivada. Por tanto, cualquier incorporación de variables adicionales deberá hacerse a partir de las propias imágenes, a través de técnicas de extracción de características (por ejemplo, histogramas de color, textura, brillo, entre otros).\n",
    "\n",
    "Este análisis confirma que el dataset se encuentra bien estructurado para un enfoque de aprendizaje supervisado basado en imágenes, en el que la salida esperada consiste en múltiples valores continuos. En etapas posteriores, será clave evaluar si se desea tratar este problema como un problema de clasificación por umbral (convirtiendo las probabilidades en etiquetas binarias), o mantener el enfoque de predicción continua por clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af2475",
   "metadata": {
    "id": "53af2475"
   },
   "source": [
    "### **1.4. Relación Entre Variables**\n",
    "---\n",
    "\n",
    "- Analice si existe alguna relación entre las variables. Puede utilizar medidas de correlación o visualizaciones.\n",
    "- Identifique si hay redundancia entre las variables para una posterior eliminación o selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e644a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b2e644a9",
    "outputId": "60a007cd-c1e9-4e89-ceb9-f206bc3d46fc"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Columnas con las probabilidades (variables objetivo)\n",
    "label_columns = df.columns[1:]  # Excluir ID\n",
    "\n",
    "# Calcular matriz de correlación (Pearson)\n",
    "corr_matrix = df[label_columns].corr()\n",
    "\n",
    "print(\"Matriz de correlación calculada.\")\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False, fmt=\".2f\", square=True, cbar_kws={\"shrink\": .5})\n",
    "plt.title(\"Mapa de calor de la matriz de correlación entre variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1tc9TLoowz1-",
   "metadata": {
    "id": "1tc9TLoowz1-"
   },
   "source": [
    "El análisis de la matriz de correlación entre las variables objetivo del dataset reveló la existencia de relaciones lineales muy fuertes entre ciertos pares de variables. En particular, se observaron dos pares con correlaciones negativas casi perfectas, lo que indica que estas variables representan características morfológicas directamente opuestas o mutuamente excluyentes dentro del cuestionario de clasificación. Esta alta correlación sugiere redundancia en la información aportada por dichas variables, lo que puede afectar la estabilidad y eficiencia de los modelos predictivos si se utilizan todas sin selección previa. Por lo tanto, resulta recomendable considerar la reducción dimensional o la eliminación de variables altamente correlacionadas para simplificar el modelo, evitar multicolinealidad y mejorar la interpretabilidad sin perder información relevante. Además, el patrón general de correlaciones en la matriz ofrece una visión clara de las relaciones morfológicas entre las distintas clases, lo que puede aportar conocimiento adicional sobre la estructura intrínseca del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dg40pVGTvh4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg40pVGTvh4s",
    "outputId": "4e396d01-69e2-404c-92e6-aae50a43ce2c"
   },
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > threshold:\n",
    "            var1 = corr_matrix.columns[i]\n",
    "            var2 = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append((var1, var2, corr_value))\n",
    "\n",
    "print(f\"Pares de variables con correlación > {threshold}:\")\n",
    "for var1, var2, corr_value in high_corr_pairs:\n",
    "    print(f\"{var1} - {var2} : {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pF8_HaZAvmWX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "pF8_HaZAvmWX",
    "outputId": "e5941ef5-a8fa-44b2-8e09-57f12963e113"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar hasta 5 pares\n",
    "num_plots = min(5, len(high_corr_pairs))\n",
    "\n",
    "for i in range(num_plots):\n",
    "    var1, var2, corr_val = high_corr_pairs[i]\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(df[var1], df[var2], alpha=0.3)\n",
    "    plt.title(f\"Scatter plot entre {var1} y {var2} (corr={corr_val:.2f})\")\n",
    "    plt.xlabel(var1)\n",
    "    plt.ylabel(var2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r71QBnRNwdF7",
   "metadata": {
    "id": "r71QBnRNwdF7"
   },
   "source": [
    "En el análisis de correlación entre las variables objetivo del dataset, se identificaron dos pares de variables con correlación casi perfecta en valor absoluto:\n",
    "\n",
    "Class1.1 y Class1.2, con correlación negativa muy fuerte de aproximadamente -0.992\n",
    "\n",
    "Class6.1 y Class6.2, con correlación negativa perfecta de -1.000\n",
    "\n",
    "Esto indica una redundancia casi total entre estas variables, ya que una se comporta como el negativo de la otra. En términos prácticos, estas variables contienen información duplicada pero invertida.\n",
    "\n",
    "Para mejorar la eficiencia y simplicidad del modelo, podriamos considerar eliminar una variable de cada par altamente correlacionado para evitar multicolinealidad, que puede perjudicar la estabilidad y generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb006272",
   "metadata": {
    "id": "fb006272"
   },
   "source": [
    "\n",
    "\n",
    "# **Diseño e implementación experimental**\n",
    "---\n",
    "\n",
    "Este notebook es una plantilla que le puede servir como guía para el tercer entregable del proyecto aplicado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bb0b6",
   "metadata": {
    "id": "cd5bb0b6"
   },
   "source": [
    "## **1. Particion del conjunto de datos**\n",
    "---\n",
    "\n",
    "La estructura básica del dataset Galaxy Zoo Challenge\n",
    "cuando se descarga usando el comando !kaggle competitions download -c galaxy-zoo-the-galaxy-challenge es obtener un archivo comprimido que, al descomprimirlo, generalmente contiene dos carpetas principales y un archivo CSV importante para las etiquetas o respuestas humanas.\n",
    "\n",
    "1. Carpeta images_training_rev1: Contiene las imágenes de galaxias que fueron clasificadas por voluntarios. Cada imagen es un archivo en formato JPG nombrado con el identificador único de la galaxia (GalaxyID) y seguido de .jpg. Por ejemplo: 100001.jpg, 100002.jpg, etc. Este dataset tiene aproximadamente 61,578 imágenes en la versión original del dataset segun la documentación, sin embargo, se advierte que puede variar según la descarga o actualización.\n",
    "\n",
    "Con este conjunto de imágenes se pueden entrenar modelos de clasificación automática para predecir las etiquetas de clasificación que dieron los voluntarios humanos.\n",
    "\n",
    "2. Carpeta images_test_rev1: Por su parte esta carpeta contiene un conjunto separado de imágenes de galaxias para las cuales se espera que se genere predicciones con el o los modelos construidos. Igual que la carpeta de entrenamiento, contiene imágenes JPG nombradas con su identificador único.\n",
    "Aproximadamente 79,975 imágenes en la versión original. Este conjunto se usa para validar la capacidad de generalizar del modelo construido. Ya que las etiquetas verdaderas de este conjunto no están disponibles (son las que se deben predecir y subir en la competencia).\n",
    "\n",
    "3. Archivo training_solutions_rev1.csv: Este archivo CSV contiene las etiquetas o soluciones \"ground truth\" basadas en los votos de los voluntarios para las imágenes en images_training_rev1.\n",
    "\n",
    "La estructura de este archivo:\n",
    "\n",
    "- Columna GalaxyID: El identificador único de cada galaxia, que también corresponde al nombre del archivo de imagen en images_training_rev1.\n",
    "\n",
    "- Columnas ClassX.Y: Cada una corresponde a la fracción (probabilidad) de votos que recibió una clase específica para una pregunta del árbol de clasificación morfológica. Por ejemplo, Class1.1 es la fracción de votos que dijeron que la galaxia es suave, Class1.2 que tiene rasgos o disco, y así sucesivamente hasta Class11.3 que indica tipos raros de galaxias o artefactos.\n",
    "\n",
    "- Valores: Son números decimales entre 0 y 1 que indican qué proporción de voluntarios seleccionó esa opción para esa galaxia. La suma de las columnas de cada pregunta es aproximadamente 1, reflejando que son probabilidades o fracciones de votos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I46TkZXyYe1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I46TkZXyYe1b",
    "outputId": "3e7d7c56-d6b9-4152-c042-3509b0583b23"
   },
   "outputs": [],
   "source": [
    "# Instalar kaggle y librerías necesarias\n",
    "!pip install -q kaggle\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Configurar kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Descargar y descomprimir dataset de Kaggle\n",
    "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge\n",
    "\n",
    "# Nombre del archivo descargado\n",
    "zip_filename = \"galaxy-zoo-the-galaxy-challenge.zip\"\n",
    "\n",
    "# Descomprimir archivo ZIP principal\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"galaxy_zoo\")\n",
    "\n",
    "# Descomprimir archivos ZIP internos\n",
    "base_folder = \"galaxy_zoo\"\n",
    "for filename in os.listdir(base_folder):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        file_path = os.path.join(base_folder, filename)\n",
    "        print(f\"Extrayendo {file_path} ...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_folder)\n",
    "        print(f\"{filename} extraído correctamente.\")\n",
    "\n",
    "# Crear carpeta limpia\n",
    "clean_folder = \"data_clean\"\n",
    "os.makedirs(clean_folder, exist_ok=True)\n",
    "\n",
    "# Archivos y carpetas que queremos conservar y mover\n",
    "keep_files = {\n",
    "    \"images_test_rev1\",\n",
    "    \"images_training_rev1\",\n",
    "    \"training_solutions_rev1.csv\"\n",
    "}\n",
    "\n",
    "# Mover archivos importantes y eliminar el resto\n",
    "for item in os.listdir(base_folder):\n",
    "    item_path = os.path.join(base_folder, item)\n",
    "    if item in keep_files:\n",
    "        dest_path = os.path.join(clean_folder, item)\n",
    "        print(f\"Moviendo {item_path} → {dest_path}\")\n",
    "        shutil.move(item_path, dest_path)\n",
    "    else:\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"Eliminando carpeta: {item_path}\")\n",
    "            shutil.rmtree(item_path)\n",
    "        else:\n",
    "            print(f\"Eliminando archivo: {item_path}\")\n",
    "            os.remove(item_path)\n",
    "\n",
    "# Eliminar carpeta original galaxy_zoo\n",
    "print(\"Eliminando carpeta galaxy_zoo...\")\n",
    "shutil.rmtree(base_folder)\n",
    "\n",
    "# Eliminar archivo ZIP principal\n",
    "if os.path.exists(zip_filename):\n",
    "    print(f\"Eliminando archivo: {zip_filename}\")\n",
    "    os.remove(zip_filename)\n",
    "\n",
    "# Verificación final: mostrar contenido de data_clean/\n",
    "print(\"\\n Contenido final en la carpeta 'data_clean':\")\n",
    "for root, dirs, files in os.walk(clean_folder):\n",
    "    level = root.replace(clean_folder, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")\n",
    "\n",
    "print(\"\\n Proceso completado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GcsMShak6un1",
   "metadata": {
    "id": "GcsMShak6un1"
   },
   "source": [
    "Cada columna ClassX.Y representa la probabilidad (fracción de votos humanos) para una respuesta específica a una pregunta en el árbol de decisión de clasificación morfológica de galaxias.\n",
    "\n",
    "El árbol tiene múltiples niveles y depende de respuestas anteriores (es decir, algunas preguntas solo se hacen si se respondió cierto valor en una pregunta anterior).\n",
    "\n",
    "En la siguiente tabla, se observa en detalle la estrucura de las preguntas:\n",
    "\n",
    "| Columna    | Pregunta                                         | Respuesta representada       |\n",
    "|------------|-------------------------------------------------|-----------------------------|\n",
    "| Class1.1   | ¿La galaxia es suave, con rasgos o estrella/artefacto? | Suave                       |\n",
    "| Class1.2   |                                                 | Con rasgos o disco           |\n",
    "| Class1.3   |                                                 | Estrella o artefacto         |\n",
    "| Class2.1   | (Si Class1.2) ¿Tiene borde visible?             | Sí (Edge-on)                |\n",
    "| Class2.2   |                                                 | No                          |\n",
    "| Class3.1   | (Si Class2.2) ¿Tiene barra?                      | Sí                          |\n",
    "| Class3.2   |                                                 | No                          |\n",
    "| Class4.1   | (Si Class1.2) ¿Cuántos brazos espirales visibles tiene? | 1                          |\n",
    "| Class4.2   |                                                 | 2                           |\n",
    "| Class4.3   |                                                 | 3                           |\n",
    "| Class4.4   |                                                 | 4                           |\n",
    "| Class4.5   |                                                 | Más de 4                    |\n",
    "| Class4.6   |                                                 | Difícil de contar           |\n",
    "| Class5.1   | ¿Tiene un anillo?                                | Sí                          |\n",
    "| Class5.2   |                                                 | No                          |\n",
    "| Class6.1   | ¿Tiene una estructura de lente?                  | Sí                          |\n",
    "| Class6.2   |                                                 | No                          |\n",
    "| Class7.1   | ¿Cuál es la orientación del centro de la galaxia? | Redonda                     |\n",
    "| Class7.2   |                                                 | Ligeramente elíptica        |\n",
    "| Class7.3   |                                                 | Muy elíptica                |\n",
    "| Class8.1   | ¿Está perturbada?                                | Sí                          |\n",
    "| Class8.2   |                                                 | No                          |\n",
    "| Class9.1   | ¿Tiene una vecina cercana?                       | Sí                          |\n",
    "| Class9.2   |                                                 | No                          |\n",
    "| Class10.1  | (Si Class9.1) ¿Está fusionándose con una vecina? | Sí                          |\n",
    "| Class10.2  |                                                 | No                          |\n",
    "| Class11.1  | ¿Hay algo raro visible?                          | Sí                          |\n",
    "| Class11.2  |                                                 | No                          |\n",
    "| Class11.3  | (Si Class11.1) ¿Cuál es la rareza?               | Otra rareza (Other)          |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ELlcMTXR7zxQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELlcMTXR7zxQ",
    "outputId": "89c79cd1-ca16-4d5a-a625-4b12c3497364"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carga del archivo con etiquetas\n",
    "labels_df = pd.read_csv('./data_clean/training_solutions_rev1.csv')\n",
    "\n",
    "# Número total de muestras\n",
    "print(f'Total de muestras: {len(labels_df)}')\n",
    "\n",
    "# Conjunto de entrenamiento y validación (80% train, 20% validación)\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Tamaño de train: {len(train_df)}')\n",
    "print(f'Tamaño de validación: {len(val_df)}')\n",
    "\n",
    "# Guarda las particiones si quieres\n",
    "train_df.to_csv('train_labels.csv', index=False)\n",
    "val_df.to_csv('val_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef6dbc",
   "metadata": {
    "id": "3fef6dbc"
   },
   "source": [
    "## **2. Selección y diseño de modelos**\n",
    "---\n",
    "\n",
    "Seleccione el/los modelo/s a explorar para aplicar sobre el conjunto de datos. Recuerde, la selección del modelo está influenciada por diferentes factores. Si el problema es de análisis de imagen, muy seguramente hay que explorar diversas redes neuronales convolucionales. Si el problema está relacionado con NLP, muy seguramente hay que explorar modelos basados en Tranformers.\n",
    "\n",
    "Además, debe definir cuál es su problema:\n",
    "\n",
    "- **Regresión**: se busca estimar un valor continúo a partir de los datos.\n",
    "- **Clasificación**: permite estimar un valor categórico a partir de los datos.\n",
    "- **Agrupamiento**: permite encontrar grupos de datos similares.\n",
    "- **Otros modelos**: recuerde que dispone de otros tipos de tareas supervisadas y no supervisadas.\n",
    "\n",
    "En cualquier caso los profundos disponibles en _TensorFlow_ constituyen una base sobre la que usted debe definir un clasificador/regresor/_encoder_/_decoder_ final, compuesto de una o más capas densas, con opción de incluir _dropout_ o capas de normalización.\n",
    "\n",
    "Justifique la escogencia y diseño de los modelos a explorar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SBH0F3X1aYkn",
   "metadata": {
    "id": "SBH0F3X1aYkn"
   },
   "source": [
    "\n",
    "\n",
    "El problema que se aborda con este dataset Galaxy Zoo es un problema de clasificación multiclase y multilabel, donde el objetivo es predecir la morfología de galaxias a partir de imágenes. Cada imagen puede tener etiquetas que representan la probabilidad de varias características morfológicas, por lo que puede considerarse una clasificación multilabel (varias etiquetas posibles por imagen) y no solo una clasificación estricta de una sola clase.\n",
    "\n",
    "\n",
    "\n",
    "| Escenario                       | Modelo a explorar                                         | Justificación                                                                                       |\n",
    "|--------------------------------|----------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| 1. CNN Convencional simple      | Redes neuronales convolucionales básicas (ej. VGG, ResNet básico) | - Las CNN son ideales para imágenes por su capacidad para extraer características espaciales.<br>- Modelos sencillos permiten entrenar rápido y probar ideas básicas.<br>- Sirve como baseline para comparar resultados.  |\n",
    "| 2. CNN profunda preentrenada (Transfer Learning) | Modelos preentrenados como ResNet50, EfficientNet, Inception con fine-tuning                     | - Aprovecha conocimiento previo entrenado en grandes datasets (ImageNet).<br>- Mejora la capacidad de generalización.<br>- Reduce tiempo y recursos para entrenar un modelo competitivo.<br>- Excelente para datasets medianos como Galaxy Zoo.  |\n",
    "\n",
    "\n",
    "\n",
    "**Justificación general del diseño**\n",
    "\n",
    "- CNNs: La estructura local y jerárquica de las CNN permite capturar características visuales fundamentales para clasificar galaxias (bordes, formas, texturas).\n",
    "\n",
    "- Transfer Learning: Usar modelos preentrenados facilita el aprendizaje de características complejas sin necesidad de gran cantidad de datos etiquetados, lo que es útil para acelerar el entrenamiento.\n",
    "\n",
    "- Diseño final: En todos los casos, se pueden  añadir capas densas finales para adaptar el modelo al número de clases multilabel, con funciones de activación adecuadas, por ejemplo sigmoid para multilabel o softmax. De igual forma técnicas de regularización como dropout o batch normalization para evitar sobreajuste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa7fd6",
   "metadata": {
    "id": "27aa7fd6"
   },
   "source": [
    "## **3. Implementación de los modelos**\n",
    "---\n",
    "\n",
    "Implemente los modelos descritos anteriormente usando herramientas de _TensorFlow_. Recuerde que puede aplicar técnicas de aumentación de datos, si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RbWFW06Daw6m",
   "metadata": {
    "id": "RbWFW06Daw6m"
   },
   "source": [
    "#**Importante: Sobre las Categoria a Predecir**\n",
    "\n",
    "\n",
    "##¿Por qué 37 categorías?\n",
    "\n",
    "El dataset **Galaxy Zoo: The Galaxy Challenge** está basado en un conjunto de preguntas sobre la morfología de galaxias. Estas preguntas fueron respondidas por voluntarios, y cada posible respuesta fue convertida en una columna del archivo `train.csv`.\n",
    "\n",
    "Cada columna `ClassX.Y` representa la probabilidad de una respuesta particular a una pregunta sobre una imagen de galaxia. Como hay varias preguntas y muchas con múltiples respuestas posibles, el total de columnas es **37**.\n",
    "\n",
    "A continuación se detalla el número de columnas por pregunta:\n",
    "\n",
    "| Pregunta | Columnas involucradas                 | Número de categorías |\n",
    "|----------|----------------------------------------|-----------------------|\n",
    "| Q1       | Class1.1, Class1.2, Class1.3           | 3                     |\n",
    "| Q2       | Class2.1, Class2.2                     | 2                     |\n",
    "| Q3       | Class3.1, Class3.2                     | 2                     |\n",
    "| Q4       | Class4.1 – Class4.6                    | 6                     |\n",
    "| Q5       | Class5.1, Class5.2                     | 2                     |\n",
    "| Q6       | Class6.1, Class6.2                     | 2                     |\n",
    "| Q7       | Class7.1, Class7.2, Class7.3           | 3                     |\n",
    "| Q8       | Class8.1, Class8.2                     | 2                     |\n",
    "| Q9       | Class9.1, Class9.2                     | 2                     |\n",
    "| Q10      | Class10.1, Class10.2                   | 2                     |\n",
    "| Q11      | Class11.1, Class11.2, Class11.3        | 3                     |\n",
    "| **Total**|                                        | **37 categorías**     |\n",
    "\n",
    "### Importante:\n",
    "\n",
    "- No es un problema de clasificación con una sola clase por muestra.\n",
    "- Es un problema de **clasificación multietiqueta**: cada imagen tiene una **distribución de probabilidades** sobre todas las clases.\n",
    "- El modelo debe predecir **valores entre 0 y 1** para **cada una de las 37 columnas**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vRl2DRmPcGyM",
   "metadata": {
    "id": "vRl2DRmPcGyM"
   },
   "outputs": [],
   "source": [
    "# Ajusta paralelismo de CPU\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HxPy6ruo_Rne",
   "metadata": {
    "id": "HxPy6ruo_Rne"
   },
   "source": [
    "# **Escenario 1: CNN Convencional Simple**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adEeQB15oxw5",
   "metadata": {
    "id": "adEeQB15oxw5"
   },
   "source": [
    "En este primer escenario se construye un modelo de aprendizaje profundo desde cero, utilizando una red neuronal convolucional (CNN) personalizada para abordar una tarea de clasificación multietiqueta sobre el conjunto de datos Galaxy Zoo. Se opta por una arquitectura sencilla mediante la API Sequential de Keras, lo que permite un control detallado sobre la topología de la red, en contraste con enfoques basados en modelos preentrenados. La arquitectura consta de tres bloques de capas convolucionales (Conv2D) seguidos por capas de agrupamiento (MaxPooling2D), con un número progresivamente mayor de filtros (32, 64 y 128), lo cual es coherente con la idea de extraer características jerárquicas desde bordes simples hasta patrones espaciales complejos. La función de activación utilizada es ReLU, estándar en la práctica moderna por su eficiencia computacional y buena propagación de gradientes. Tras la etapa convolucional, las salidas se aplanan (Flatten) y se procesan por una capa densa de 128 unidades con activación ReLU, seguida por un Dropout del 50% que actúa como regularizador para reducir el sobreajuste. La capa de salida tiene 37 neuronas (una por clase), cada una con activación sigmoide, lo que permite emitir probabilidades independientes para cada etiqueta, asumiendo que no existe una exclusión mutua entre clases, lo cual es correcto en el contexto multietiqueta.\n",
    "\n",
    "Se emplea la función de pérdida binary_crossentropy, adecuada para problemas donde cada etiqueta se considera una tarea de clasificación binaria independiente. La métrica utilizada para monitorear el aprendizaje es la precisión (accuracy), aunque esta métrica puede ser poco representativa en problemas multilabel y desequilibrados. El modelo es compilado con el optimizador Adam, ampliamente adoptado en visión por computador por su capacidad de adaptación del paso de aprendizaje y su eficacia en problemas no convexos.\n",
    "\n",
    "El flujo de datos se organiza mediante ImageDataGenerator, especificando un reescalamiento de los valores de píxeles entre 0 y 1 (rescale=1./255), lo cual es una práctica habitual que estabiliza el proceso de entrenamiento al trabajar en rangos de activación más controlados. Se define una partición interna del conjunto de entrenamiento utilizando validation_split=0.2, dividiendo automáticamente los datos en entrenamiento y validación. Se utiliza el método flow_from_dataframe, que permite enlazar imágenes con etiquetas multiclase representadas en columnas, especificando class_mode='raw' para que se mantenga la salida como vectores binarios completos, sin codificación categórica. Las rutas de las imágenes se construyen automáticamente concatenando los identificadores de galaxias con la extensión .jpg, lo que implica que el conjunto de datos debe estar correctamente organizado y que los nombres de archivo deben coincidir con los identificadores en el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6UJCQWI3_ZDE",
   "metadata": {
    "id": "6UJCQWI3_ZDE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parámetros\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 37  # Número de clases en Galaxy Zoo\n",
    "\n",
    "# Modelo CNN simple\n",
    "def create_simple_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='sigmoid')  # sigmoid para multilabel\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6AfACpzh_gcq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "6AfACpzh_gcq",
    "outputId": "be5b105b-e6e4-4cde-9df8-fe96bfc81125"
   },
   "outputs": [],
   "source": [
    "model = create_simple_cnn()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',   # para multilabel clasificación\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9wRZQuGn_n4_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wRZQuGn_n4_",
    "outputId": "5aa3effd-652d-4a39-c005-8d701502aa3a"
   },
   "outputs": [],
   "source": [
    "# --- Preparar generadores de datos ---\n",
    "\n",
    "# Aquí debes adaptar 'train_df' para que contenga las columnas 'id' (nombre archivo sin extensión) y las columnas de clases\n",
    "# Suponiendo que las imágenes están en 'images_training_rev1/' y los archivos son JPG\n",
    "\n",
    "# Crear columna 'id' con nombres de archivos\n",
    "train_df['id'] = train_df['GalaxyID'].astype(str) + '.jpg'\n",
    "\n",
    "# Obtener columnas de etiquetas (multilabel)\n",
    "label_columns = [col for col in train_df.columns if col.startswith('Class')]\n",
    "\n",
    "# Tamaño de imagen y batch size (ajústalos a tu caso)\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Crear generadores\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='./data_clean/images_training_rev1/',\n",
    "    x_col='id',\n",
    "    y_col=label_columns,\n",
    "    subset='training',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',  # multilabel\n",
    "    target_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='./data_clean/images_training_rev1/',\n",
    "    x_col='id',\n",
    "    y_col=label_columns,\n",
    "    subset='validation',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wPKgnh4oo9Pm",
   "metadata": {
    "id": "wPKgnh4oo9Pm"
   },
   "source": [
    "Durante el entrenamiento, se utiliza una política de detención temprana (EarlyStopping) monitorizando la pérdida de validación con una paciencia de 3 épocas, y se activa restore_best_weights=True para conservar los pesos asociados al menor valor de val_loss. Este enfoque evita el sobreentrenamiento, mejorando la generalización del modelo al detener el aprendizaje cuando el modelo empieza a memorizar el conjunto de entrenamiento. El modelo se entrena por un máximo de 20 épocas, aunque en la práctica la política de EarlyStopping suele intervenir antes si no se observa mejora en la pérdida de validación. La estrategia de entrenamiento se apoya exclusivamente en los datos proporcionados por los generadores, lo que permite una gestión eficiente de memoria y una carga en tiempo real desde disco. Aunque se define una instancia de ImageDataGenerator, no se incorporan transformaciones de aumento de datos (rotación, traslación, zoom, inversión horizontal), lo que podría representar una oportunidad perdida para mejorar la robustez del modelo frente a variaciones geométricas de las imágenes astronómicas.\n",
    "\n",
    "El modelo resultante podria ser funcional y adecuado para tareas de clasificación multietiqueta básicas en contextos donde se desea tener control total sobre cada etapa del pipeline de aprendizaje profundo, y representa un esquema claro que pone en práctica desde la arquitectura de red hasta la gestión eficiente de datos. Ademas, permite evaluar de manera explícita el comportamiento del entrenamiento sin depender de abstracciones asociadas a modelos complejos preentrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VeytFy_9AY5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeytFy_9AY5z",
    "outputId": "e1563841-c5c0-4ac5-e0ae-22514a198b44"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qQBHi0JYd6ZQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "qQBHi0JYd6ZQ",
    "outputId": "e90414a8-bbb5-46ef-d566-497bc350eb59"
   },
   "outputs": [],
   "source": [
    "# Pérdida\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oYvKejSbeDY5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "oYvKejSbeDY5",
    "outputId": "dc419683-a137-470d-be9c-be7fee8b07b2"
   },
   "outputs": [],
   "source": [
    "if 'accuracy' in history.history:\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "    plt.title('Precisión')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v0DI6V5dc3HC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0DI6V5dc3HC",
    "outputId": "bcd78825-b77f-43dc-fda6-8bd94cf25222"
   },
   "outputs": [],
   "source": [
    "model.save('modelo_entrenado_escenario_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4koeYCveJ7J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4koeYCveJ7J",
    "outputId": "425bbbf2-3f94-469a-bb3e-6647278c8826"
   },
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(validation_generator)\n",
    "print(f'Pérdida en validación: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vJGiUOHYm522",
   "metadata": {
    "id": "vJGiUOHYm522"
   },
   "source": [
    "#**Conclusiones Escenario 1**\n",
    "\n",
    "El entrenamiento del modelo CNN personalizado muestra una evolución coherente y progresiva tanto en la precisión como en la pérdida, lo que permite inferir una dinámica de aprendizaje estable y eficiente. En la primera época, el modelo parte de una precisión relativamente baja (0.5150), con una pérdida de entrenamiento de 0.3257, lo cual es esperable dada la inicial aleatoriedad de los pesos y la naturaleza del problema multilabel. Sin embargo, ya desde la primera validación se evidencia un mejor rendimiento relativo en el conjunto de validación (val_accuracy = 0.6703), sugiriendo que el modelo comienza a capturar patrones generales útiles desde las primeras iteraciones.\n",
    "\n",
    "A partir de la segunda época, la mejora es significativa: la precisión de entrenamiento asciende rápidamente a 0.6341, y la pérdida disminuye de forma sustancial a 0.2694. En validación, se mantiene una tendencia similar (val_accuracy = 0.7244), indicando que el modelo no solo está aprendiendo las regularidades del conjunto de entrenamiento, sino que está generalizando correctamente. Este comportamiento continúa a lo largo de las siguientes épocas, con mejoras sostenidas hasta la época 5, donde se alcanza una precisión de entrenamiento de 0.7194 y una de validación de 0.7564. Cabe destacar que, a partir de este punto, las mejoras se tornan más graduales, como es característico de curvas de aprendizaje donde el modelo se aproxima a su capacidad representacional máxima sin cambios arquitectónicos ni aumentos de complejidad.\n",
    "\n",
    "En términos de pérdida, se observa una disminución constante desde la época 1 hasta la 10, con valores que pasan de 0.3257 a 0.2451 en entrenamiento y de 0.2625 a 0.2458 en validación. La diferencia entre ambas curvas es pequeña y estable, lo cual es una señal favorable de que no está ocurriendo sobreajuste severo. La cercanía entre loss y val_loss refuerza la idea de que el modelo se mantiene dentro de un régimen de generalización efectiva, en gran parte apoyado por la regularización vía Dropout y una arquitectura que, sin ser profunda, es suficiente para capturar las estructuras presentes en el conjunto Galaxy Zoo.\n",
    "\n",
    "Es importante mencionar que la métrica accuracy en contextos multilabel puede tener limitaciones: mide cuántas predicciones completas coinciden con las etiquetas verdaderas, lo que tiende a ser un criterio estricto y puede subestimar la calidad del modelo en presencia de etiquetas parcialmente acertadas. Por lo que en posteriores etapas del proyecto se plateara utilizar otras metricas para evaluar el rendimiento. A pesar de ello, el comportamiento ascendente sostenido de esta métrica indica una progresiva mejora en la capacidad del modelo para capturar múltiples etiquetas de manera simultánea.\n",
    "\n",
    "El modelo no ha convergido por completo a un estado de estancamiento, pero la tasa de mejora desde la época 7 en adelante es marginal. Por ejemplo, la precisión de validación oscila entre 0.7646 y 0.7705 entre las épocas 7 y 10, y la pérdida fluctúa levemente alrededor de 0.245. Estos valores sugieren que el modelo se encuentra en una fase de saturación del aprendizaje y que una continuación indefinida del entrenamiento no aportaría beneficios significativos, haciendo adecuado el uso de una política de detención temprana.\n",
    "\n",
    "El comportamiento del modelo es consistente con una arquitectura bien calibrada para un problema de clasificación multietiqueta moderadamente complejo. Las tasas de precisión logradas son competitivas para una CNN entrenada desde cero, sin preentrenamiento, ni técnicas de aumento de datos, ni ajustes finos hiperparamétricos, lo que subraya la capacidad del modelo para aprender representaciones útiles directamente desde los datos en bruto. Este desempeño abre la puerta a extensiones futuras como la incorporación de transformaciones geométricas mediante ImageDataGenerator, el uso de métricas más específicas como F1-score o AUC por clase, o incluso el reemplazo del backbone por arquitecturas más profundas o preentrenadas como se pueden realizar en otros escenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2r4-1BqzHO1K",
   "metadata": {
    "id": "2r4-1BqzHO1K"
   },
   "source": [
    "# **Escenario 2: CNN profunda preentrenada (Transfer Learning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPXCb8MGiA2j",
   "metadata": {
    "id": "zPXCb8MGiA2j"
   },
   "source": [
    "En este escenario se emplea la técnica utilizada en visión por computador llamada Transfer Learning (aprendizaje por transferencia). Esta técnica consiste en reutilizar un modelo de red neuronal profunda previamente entrenado en un conjunto de datos grande y general, como ImageNet, para resolver una tarea diferente pero relacionada. En nuestro caso, se aplica a la clasificación multietiqueta de galaxias en el conjunto de datos Galaxy Zoo.\n",
    "\n",
    "Este enfoque es especialmente útil cuando no se dispone de una gran cantidad de datos etiquetados, que vale aclarar no es nuestro caso. Sin embargo, entrenar un modelo profundo desde cero es computacionalmente costoso y requiere mucho tiempo. Aprovechando los pesos aprendidos en tareas generales, el modelo puede adaptarse eficientemente a nuevas tareas específicas.\n",
    "\n",
    "En la implementación se utiliza ResNet50, una red convolucional profunda de 50 capas con arquitectura residual, que facilita el entrenamiento de redes muy profundas mediante conexiones directas entre capas no consecutivas. Este modelo, entrenado previamente con millones de imágenes de ImageNet, ha aprendido a reconocer patrones visuales genéricos como bordes, texturas y formas que también pueden ser útiles para describir galaxias.\n",
    "\n",
    "Para adaptar ResNet50 a nuestra tarea:\n",
    "\n",
    "- Se carga el modelo sin su capa de salida original (include_top=False), usándolo como extractor de características.\n",
    "- Se congelan sus capas para preservar los pesos entrenados.\n",
    "- Se añaden nuevas capas: una de pooling global, dropout para reducir el sobreajuste y una capa final con 37 neuronas (una por cada etiqueta del conjunto Galaxy Zoo), usando activación sigmoide, ya que se trata de un problema de clasificación multietiqueta (una imagen puede tener múltiples etiquetas activas).\n",
    "\n",
    "Los datos se cargan mediante generadores de imágenes que:\n",
    "\n",
    "- Reescalan los píxeles al rango [0, 1],\n",
    "- Aplican aumentos de datos al conjunto de entrenamiento (rotación, zoom, espejo horizontal),\n",
    "\n",
    "Y leen tanto las imágenes como las etiquetas desde un archivo .csv con el GalaxyID y 37 columnas adicionales correspondientes a las clases.\n",
    "\n",
    "Durante la primera etapa de entrenamiento, solo se ajustan las capas añadidas, manteniendo el modelo base congelado. Esto acelera el proceso y evita que el modelo sobreentrene.\n",
    "\n",
    "Después, se realiza una segunda fase de ajuste fino (fine-tuning), donde se descongelan las últimas capas de ResNet50 y se reentrena el modelo con una tasa de aprendizaje más baja. Esto permite que las capas superiores del modelo base se adapten a las características particulares de las imágenes de galaxias sin perder el conocimiento previamente adquirido.\n",
    "\n",
    "Este enfoque ofrece varias ventajas:\n",
    "\n",
    "- Reduce el tiempo de entrenamiento,\n",
    "- Requiere menos datos etiquetados,\n",
    "- Mejora la generalización del modelo,\n",
    "\n",
    "Permitiendo obtener resultados competitivos en dominios complejos como es este problema de la astronomía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VMTOvU6_fWE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMTOvU6_fWE3",
    "outputId": "f1ac51ca-73e1-41c5-daff-9fbfd097e13d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Parámetros\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Directorios\n",
    "train_images_dir = './data_clean/images_training_rev1/'\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "val_labels = pd.read_csv('val_labels.csv')\n",
    "\n",
    "# Asegurarte de que GalaxyID sea string y añadir extensión .jpg\n",
    "train_labels['GalaxyID'] = train_labels['GalaxyID'].astype(str)\n",
    "val_labels['GalaxyID'] = val_labels['GalaxyID'].astype(str)\n",
    "train_labels['filename'] = train_labels['GalaxyID'] + '.jpg'\n",
    "val_labels['filename'] = val_labels['GalaxyID'] + '.jpg'\n",
    "\n",
    "# Columnas de clases\n",
    "class_columns = [col for col in train_labels.columns if col.startswith('Class')]\n",
    "\n",
    "# Generadores con aumentos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_labels,\n",
    "    directory=train_images_dir,\n",
    "    x_col='filename',\n",
    "    y_col=class_columns,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_labels,\n",
    "    directory=train_images_dir,\n",
    "    x_col='filename',\n",
    "    y_col=class_columns,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "# Modelo base\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Capas superiores personalizadas\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(len(class_columns), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilar\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS)\n",
    "\n",
    "# Fine-tuning: desbloquear parte final de la red\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompilar con menor tasa de aprendizaje\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reentrenar\n",
    "fine_tune_epochs = 5\n",
    "history_fine = model.fit(train_generator, validation_data=val_generator, epochs=fine_tune_epochs)\n",
    "\n",
    "# Guardar modelo\n",
    "model.save('galaxy_zoo_resnet50_multiclass_finetuned.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WR-rqi5Zncn2",
   "metadata": {
    "id": "WR-rqi5Zncn2"
   },
   "source": [
    "#**Conclusiones Escenario 2**\n",
    "\n",
    "El entrenamiento de un modelo de clasificación multietiqueta utilizando la arquitectura ResNet50, aplicada al conjunto de datos Galaxy Zoo, demuestra la eficacia del aprendizaje por transferencia (transfer learning) en tareas de visión por computador donde se dispone de un conjunto de datos con etiquetas complejas pero no necesariamente masivo. El proceso se desarrolló en dos fases: una primera etapa de entrenamiento con las capas convolucionales de la red base congeladas, y una segunda etapa de ajuste fino (fine-tuning) en la que se descongelaron las capas superiores del modelo preentrenado en ImageNet.\n",
    "\n",
    "Durante las primeras diez épocas de entrenamiento con la red congelada, el modelo logró capturar patrones representativos del conjunto de datos, con una pérdida de validación que decreció progresivamente desde 0.3001 hasta 0.2965. Esta tendencia sugiere que las capas densas añadidas al final de la arquitectura fueron capaces de adaptar las representaciones genéricas de la ResNet50 a las características específicas del dominio astronómico de Galaxy Zoo. La precisión (accuracy) de validación se mantuvo estable, oscilando alrededor de 0.59, lo cual es coherente con el comportamiento esperado en problemas de clasificación multietiqueta, donde la métrica de accuracy puede ser conservadora o incluso engañosa si no se tiene en cuenta el carácter parcial de las etiquetas.\n",
    "\n",
    "La segunda fase, correspondiente al fine-tuning del modelo, implicó la actualización de pesos en las capas convolucionales superiores de ResNet50. Esto permitió refinar las representaciones jerárquicas obtenidas en la preentrenamiento y ajustarlas de forma más específica al dominio del problema. En esta etapa se evidenció un incremento más pronunciado en la precisión de entrenamiento, alcanzando un 65.3% en la última época, y un leve aumento en la precisión de validación (0.6086). Más relevante aún, la pérdida de validación se redujo hasta 0.2953, lo cual sugiere una mejora real en la capacidad predictiva del modelo. Cabe destacar que estas mejoras, si bien modestas en magnitud, indican que el modelo no cayó en sobreajuste pese al desbloqueo parcial de la red base, lo cual se puede atribuir a un buen manejo del learning rate y probablemente al uso de técnicas de regularización o data augmentation.\n",
    "\n",
    "Sin embargo, es importante enfatizar que la accuracy utilizada como métrica principal tiene limitaciones importantes en tareas multietiqueta, dado que no captura la granularidad de las predicciones parciales o su proximidad al vector de etiquetas verdadero. En este tipo de problemas, métricas como el F1-score por etiqueta, el promedio ponderado de precision/recall, el AUC por clase o incluso el Hamming loss ofrecen una imagen más precisa y detallada del rendimiento del modelo. La inclusión de estas métricas será clave en futuras iteraciones del proceso de evaluación y optimización.\n",
    "\n",
    "Este entrenamiento muestra una aplicación efectiva de transfer learning con fine-tuning en un contexto real de clasificación multietiqueta. El modelo logró converger a una solución con pérdida estable y precisión competitiva, aunque es necasario complementar este análisis con métricas más representativas del problema. La arquitectura ResNet50, aun siendo generalista, mostró una buena capacidad de adaptación al dominio astronómico, y podría seguir optimizándose mediante el ajuste de hiperparámetros, el aumento sintético de datos o el diseño de una arquitectura específica para multietiquetas si se desea avanzar en desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98c1e5",
   "metadata": {
    "id": "db98c1e5"
   },
   "source": [
    "\n",
    "\n",
    "# **Entrenamiento y Validación**\n",
    "---\n",
    "\n",
    "Este notebook es una plantilla que le puede servir como guía para el cuarto entregable del proyecto aplicado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04b1d3",
   "metadata": {
    "id": "8a04b1d3"
   },
   "source": [
    "## **1. Entrenamiento del Modelo y Selección de Hiperparámetros**\n",
    "---\n",
    "\n",
    "Si está utilizando un modelo que requiere entrenamiento, deberá entrenarlo y seleccionar un conjunto de hiperparámetros válido para el mismo. Recuerde que tiene diversas erramientas para hacer validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e6e40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d2e6e40",
    "outputId": "e73c7d76-4d49-4b66-b472-98877943f3a5"
   },
   "outputs": [],
   "source": [
    "# ---**INGRESE SU CÓDIGO**---\n",
    "# Instalar kaggle y librerías necesarias\n",
    "!pip install -q kaggle\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurar kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Descargar y descomprimir dataset de Kaggle\n",
    "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge\n",
    "\n",
    "# Nombre del archivo descargado\n",
    "zip_filename = \"galaxy-zoo-the-galaxy-challenge.zip\"\n",
    "\n",
    "# Descomprimir archivo ZIP principal\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"galaxy_zoo\")\n",
    "\n",
    "# Descomprimir archivos ZIP internos\n",
    "base_folder = \"galaxy_zoo\"\n",
    "for filename in os.listdir(base_folder):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        file_path = os.path.join(base_folder, filename)\n",
    "        print(f\"Extrayendo {file_path} ...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_folder)\n",
    "        print(f\"{filename} extraído correctamente.\")\n",
    "\n",
    "# Crear carpeta limpia\n",
    "clean_folder = \"data_clean\"\n",
    "os.makedirs(clean_folder, exist_ok=True)\n",
    "\n",
    "# Archivos y carpetas que queremos conservar y mover\n",
    "keep_files = {\n",
    "    \"images_test_rev1\",\n",
    "    \"images_training_rev1\",\n",
    "    \"training_solutions_rev1.csv\"\n",
    "}\n",
    "\n",
    "# Mover archivos importantes y eliminar el resto\n",
    "for item in os.listdir(base_folder):\n",
    "    item_path = os.path.join(base_folder, item)\n",
    "    if item in keep_files:\n",
    "        dest_path = os.path.join(clean_folder, item)\n",
    "        print(f\"Moviendo {item_path} → {dest_path}\")\n",
    "        shutil.move(item_path, dest_path)\n",
    "    else:\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"Eliminando carpeta: {item_path}\")\n",
    "            shutil.rmtree(item_path)\n",
    "        else:\n",
    "            print(f\"Eliminando archivo: {item_path}\")\n",
    "            os.remove(item_path)\n",
    "\n",
    "# Eliminar carpeta original galaxy_zoo\n",
    "print(\"Eliminando carpeta galaxy_zoo...\")\n",
    "shutil.rmtree(base_folder)\n",
    "\n",
    "# Eliminar archivo ZIP principal\n",
    "if os.path.exists(zip_filename):\n",
    "    print(f\"Eliminando archivo: {zip_filename}\")\n",
    "    os.remove(zip_filename)\n",
    "\n",
    "# Verificación final: mostrar contenido de data_clean/\n",
    "print(\"\\nContenido final en la carpeta 'data_clean':\")\n",
    "for root, dirs, files in os.walk(clean_folder):\n",
    "    level = root.replace(clean_folder, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")\n",
    "\n",
    "print(\"\\nProceso completado correctamente.\")\n",
    "\n",
    "# Carga del archivo con etiquetas\n",
    "labels_df = pd.read_csv('./data_clean/training_solutions_rev1.csv')\n",
    "\n",
    "# Tomar solo el 50% de los datos\n",
    "labels_df = labels_df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Número total de muestras\n",
    "print(f'Total de muestras (50%): {len(labels_df)}')\n",
    "\n",
    "# Conjunto de entrenamiento y validación (80% train, 20% validación)\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Tamaño de train: {len(train_df)}')\n",
    "print(f'Tamaño de validación: {len(val_df)}')\n",
    "\n",
    "# Guarda las particiones si quieres\n",
    "train_df.to_csv('train_labels.csv', index=False)\n",
    "val_df.to_csv('val_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vVKIF-AYNtP3",
   "metadata": {
    "id": "vVKIF-AYNtP3"
   },
   "outputs": [],
   "source": [
    "# Ajusta paralelismo de CPU\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2YFmmiK3JVJX",
   "metadata": {
    "id": "2YFmmiK3JVJX"
   },
   "source": [
    "# **Reducción Dimensional del Conjunto de Datos**\n",
    "\n",
    "Se abordó el desafío de clasificación de galaxias del conjunto de datos Galaxy Zoo, con el objetivo de diseñar un flujo de preprocesamiento eficiente y compatible con recursos computacionales limitados. El conjunto de datos consiste en miles de imágenes astronómicas que muestran diversas morfologías galácticas, lo cual representa una valiosa oportunidad para el desarrollo y evaluación de modelos de aprendizaje profundo, pero también plantea retos significativos en términos de almacenamiento, uniformidad y procesamiento.\n",
    "\n",
    "Considerando la ausencia de acceso a unidades de procesamiento gráfico (GPU) de alto rendimiento, se implementó un pipeline de preprocesamiento que optimiza las imágenes para su uso en redes neuronales convolucionales, reduciendo la carga computacional sin comprometer la calidad visual necesaria para la tarea de clasificación.\n",
    "\n",
    "El proceso comienza con la carga de bibliotecas esenciales como PIL para la manipulación de imágenes, pandas para el manejo estructurado de los metadatos y matplotlib para la visualización gráfica. Se establecieron parámetros clave para el procesamiento, tales como un recorte centrado de 180x180 píxeles y una redimensión posterior a 160x160 píxeles. Estas dimensiones fueron elegidas para equilibrar la fidelidad visual de las galaxias con la necesidad de reducir el tamaño de entrada del modelo.\n",
    "\n",
    "El procedimiento de transformación se llevó a cabo mediante dos funciones principales. La primera, crop_center, recorta cada imagen desde el centro, eliminando posibles áreas irrelevantes o ruido en los bordes, y manteniendo la región más significativa de la imagen. La segunda, preprocess_and_save, recorre un DataFrame que contiene los identificadores únicos de cada galaxia (GalaxyID), abre las imágenes correspondientes desde un directorio origen, las convierte a formato RGB, les aplica el recorte y redimensión descritos y finalmente guarda las imágenes procesadas en un directorio destino.\n",
    "\n",
    "Adicionalmente, se desarrolló una función auxiliar (show_preprocessed_samples) que permite visualizar una muestra representativa de las imágenes ya procesadas. Esta herramienta resulta útil para la verificación cualitativa de la integridad del preprocesamiento, mostrando un conjunto de ejemplos con sus respectivos identificadores en una cuadrícula gráfica.\n",
    "\n",
    "El flujo descrito fue aplicado tanto al conjunto de entrenamiento como al de validación, utilizando rutas diferenciadas para los directorios de entrada y salida. El resultado es un conjunto de imágenes homogéneo y reducido en tamaño, preparado para ser utilizado como entrada en modelos de Deep Learning sin requerimientos computacionales elevados.\n",
    "\n",
    "Este enfoque permitió, mediante técnicas simples y eficientes, generar un conjunto de datos estandarizado y manejable, apto para entrenar modelos de clasificación en contextos donde los recursos disponibles son limitados. La experiencia pone de manifiesto la importancia del preprocesamiento cuidadoso en proyectos de aprendizaje profundo, especialmente cuando se trabaja con datos visuales complejos y capacidad computacional restringida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vvSI9G57T2xL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "id": "vvSI9G57T2xL",
    "outputId": "24d3815e-396d-48c5-e021-3935d6609243"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Parámetros\n",
    "CROP_SIZE = 180  # Tamaño del recorte centrado cuadrado\n",
    "IMG_SIZE = 160   # Tamaño final redimensionado\n",
    "NUM_SAMPLES_TO_SHOW = 10\n",
    "\n",
    "# Función para recorte centrado\n",
    "def crop_center(img, crop_size):\n",
    "    width, height = img.size\n",
    "    left = (width - crop_size) // 2\n",
    "    top = (height - crop_size) // 2\n",
    "    right = left + crop_size\n",
    "    bottom = top + crop_size\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "# Función para preprocesar y guardar imágenes\n",
    "def preprocess_and_save(df, original_dir, target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    for idx, row in df.iterrows():\n",
    "        img_id = str(row['GalaxyID']) + '.jpg'\n",
    "        img_path = os.path.join(original_dir, img_id)\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_cropped = crop_center(img, CROP_SIZE)\n",
    "            img_final = img_cropped.resize((IMG_SIZE, IMG_SIZE))\n",
    "            img_final.save(os.path.join(target_dir, img_id))\n",
    "\n",
    "# Función para mostrar imágenes preprocesadas\n",
    "def show_preprocessed_samples(df, input_dir, n=NUM_SAMPLES_TO_SHOW):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if count >= n:\n",
    "            break\n",
    "        img_id = str(row['GalaxyID']) + '.jpg'\n",
    "        img_path = os.path.join(input_dir, img_id)\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path)\n",
    "            plt.subplot(2, 5, count + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"ID: {row['GalaxyID']}\")\n",
    "            count += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========== CONFIGURACIÓN ==========\n",
    "# Asegúrate de agregar la columna 'filename'\n",
    "train_df['filename'] = train_df['GalaxyID'].astype(str) + '.jpg'\n",
    "val_df['filename'] = val_df['GalaxyID'].astype(str) + '.jpg'\n",
    "\n",
    "# Directorios de entrada (originales) y salida (redimensionados)\n",
    "original_train_dir = './data_clean/images_training_rev1'\n",
    "resized_train_dir = './data_clean/images_training_color'\n",
    "resized_val_dir = './data_clean/images_validation_color'\n",
    "\n",
    "# ======= Preprocesamiento y guardado =======\n",
    "# Para entrenamiento\n",
    "preprocess_and_save(train_df, original_train_dir, resized_train_dir)\n",
    "# Para validación (usando el mismo directorio original)\n",
    "preprocess_and_save(val_df, original_train_dir, resized_val_dir)\n",
    "# ======= Mostrar muestras =======\n",
    "print(\"Ejemplos del conjunto de entrenamiento:\")\n",
    "show_preprocessed_samples(train_df, resized_train_dir)\n",
    "print(\"Ejemplos del conjunto de validación:\")\n",
    "show_preprocessed_samples(val_df, resized_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WD1XT80ILMrW",
   "metadata": {
    "id": "WD1XT80ILMrW"
   },
   "source": [
    "## **2. Evaluación o Aplicación del modelo**\n",
    "---\n",
    "\n",
    "Para realizar un entrenamiento y una aplicación del modelo se implementó una estrategia de transferencia de aprendizaje basada en la arquitectura MobileNetV2, con el fin de clasificar imágenes de galaxias pertenecientes al desafío Galaxy Zoo. La elección de este modelo responde a la necesidad de optimizar el uso de recursos computacionales, dada su eficiencia y bajo costo en términos de memoria y procesamiento, sin sacrificar capacidad representacional.\n",
    "\n",
    "Para el entrenamiento del modelo, se recurre al conjuntos de datos previamente preprocesado y redimensionado. Se utilizó ImageDataGenerator de TensorFlow para crear generadores de imágenes que alimentaran el modelo de forma eficiente, permitiendo además la aplicación de técnicas de aumento de datos (data augmentation) sobre el conjunto de entrenamiento. Este proceso incluyó transformaciones como giros aleatorios y espejado horizontal, mientras que las imágenes de validación únicamente fueron reescaladas a valores entre 0 y 1.\n",
    "\n",
    "Los archivos de imagen se asociaron a sus respectivas etiquetas multiclase a través de la función flow_from_dataframe, que permitió definir las columnas correspondientes a las etiquetas galácticas como salida del modelo. El parámetro class_mode='raw' fue utilizado para soportar esta estructura de multietiquetado, en la que una imagen puede pertenecer simultáneamente a más de una clase morfológica.\n",
    "\n",
    "Se utilizó como modelo base MobileNetV2, precargado con pesos entrenados en ImageNet y sin su capa superior (include_top=False). Este modelo base se  mantuvo congelado durante una primera etapa de entrenamiento, a fin de preservar el conocimiento adquirido y limitar el número de parámetros ajustables, algo crucial en escenarios con limitaciones de hardware.\n",
    "\n",
    "Sobre la salida del modelo base, se añadió una capa de pooling global, seguida por una capa de dropout con una tasa del 30% para mitigar el sobreajuste, y finalmente una capa densa con función de activación sigmoid que produce una salida continua entre 0 y 1 para cada una de las clases posibles, lo cual es adecuado para este tipo de tareas multietiqueta.\n",
    "\n",
    "El modelo se compiló utilizando el optimizador Adam, con una función de pérdida binaria (binary_crossentropy) y como métrica de evaluación la exactitud (accuracy). Se entrenó inicialmente durante cinco épocas, manteniendo congeladas todas las capas del modelo base.\n",
    "\n",
    "Posteriormente, se llevó a cabo un proceso de fine-tuning o ajuste fino. Para ello, se descongelaron parcialmente las capas del modelo base, específicamente a partir de la capa 100, permitiendo que las capas superiores se ajustaran a las características particulares del conjunto de datos astronómicos. Esta segunda etapa de entrenamiento se ejecutó durante cinco épocas adicionales, utilizando una tasa de aprendizaje más baja (1e-5) para evitar alteraciones bruscas en los pesos ya entrenados.\n",
    "\n",
    "Finalizado el entrenamiento, el modelo fue guardado en disco bajo el nombre modelo_galaxias_mobilenetv2.h5, con el objetivo de facilitar su reutilización o evaluación posterior sin necesidad de reentrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dec8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Preparar generadores para TensorFlow\n",
    "# Crear columna con nombres de archivo para flow_from_dataframe\n",
    "train_df['filename'] = train_df['GalaxyID'].astype(str) + '.jpg'\n",
    "val_df['filename'] = val_df['GalaxyID'].astype(str) + '.jpg'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = train_df.shape[1] - 2  # Quitando GalaxyID y filename\n",
    "\n",
    "# Etiquetas: columnas desde la segunda en adelante (exceptuando GalaxyID y filename)\n",
    "label_cols = train_df.columns.difference(['GalaxyID', 'filename']).tolist()\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=20)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=resized_train_dir,\n",
    "    x_col='filename',\n",
    "    y_col=label_cols,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',  # usado para multietiquetas\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=resized_val_dir,\n",
    "    x_col='filename',\n",
    "    y_col=label_cols,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=False)\n",
    "\n",
    "# Modelo Transfer Learning MobileNetV2\n",
    "base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)  # multietiqueta\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento inicial\n",
    "EPOCHS_INITIAL = 5\n",
    "history_initial = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_INITIAL\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "EPOCHS_FINE = 5\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_FINE\n",
    ")\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save('modelo_galaxias_mobilenetv2.h5')\n",
    "print(\"Modelo guardado en modelo_galaxias_mobilenetv2.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d49edd",
   "metadata": {},
   "source": [
    "Con el objetivo de visualizar el comportamiento del modelo durante todo el proceso de entrenamiento, se implementó un procedimiento para combinar los historiales de entrenamiento correspondientes a las etapas de transfer learning y fine-tuning. Para ello, se definió una función que toma los diccionarios de historial generados por Keras (history_initial y history_fine) y concatena sus valores en una estructura unificada. Esta consolidación facilita el análisis conjunto de la evolución del modelo a lo largo de todas las épocas de entrenamiento.\n",
    "\n",
    "Se desarrolló una función de visualización que permite representar gráficamente las curvas de pérdida (loss) y precisión (accuracy) tanto para los datos de entrenamiento como para los de validación. La visualización distingue claramente entre las dos fases del proceso de aprendizaje mediante el uso de zonas sombreadas: una azul para la etapa inicial de transfer learning y otra verde para la fase posterior de fine-tuning. Esta segmentación permite apreciar las diferencias en el comportamiento del modelo entre ambas fases.\n",
    "\n",
    "Las curvas de pérdida muestran cómo evoluciona la función objetivo durante el entrenamiento, permitiendo detectar posibles problemas de sobreajuste o subajuste. Por su parte, las curvas de precisión permiten observar la capacidad del modelo para realizar predicciones correctas a lo largo de las épocas. En cada gráfico se incluyen etiquetas, leyendas y anotaciones que permiten interpretar fácilmente las transiciones entre las distintas etapas del proceso."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
